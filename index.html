<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-09-15 qui 21:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Tiago Oliveira Weber</title>
<meta name="author" content="tweber" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="themes/styles/bigblow/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="themes/styles/bigblow/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="themes/styles/bigblow/css/hideshow.css"/>
<link rel="stylesheet" type="text/css" href="themes/styles/bigblow/css/mine.css"/>
<script type="text/javascript" src="themes/styles/bigblow/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/bigblow.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/hideshow.js"></script>
<script type="text/javascript" src="themes/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="themes/styles/bigblow/js/mine.js"></script>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-79541283-1', 'auto');
ga('send', 'pageview');
</script>
<script language="JavaScript">
<!--
function autoResize(id){
var newheight;
var newwidth;

if(document.getElementById){
newheight = document.getElementById(id).contentWindow.document .body.scrollHeight;
newwidth = document.getElementById(id).contentWindow.document .body.scrollWidth;
}

document.getElementById(id).height = (newheight) + "px";
document.getElementById(id).width = (newwidth) + "px";
}
//-->
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Tiago Oliveira Weber</h1>

<div id="outline-container-org50eb8bd" class="outline-2">
<h2 id="org50eb8bd">About</h2>
<div class="outline-text-2" id="text-org50eb8bd">

<div id="org8beaa7c" class="figure">
<p><img src="img/photob.jpg" alt="photob.jpg" width="200px image" title="Photo" align="right" /> 
</p>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">I am currently a professor at the Federal University of Rio Grande do Sul (UFRGS), Porto Alegre, Brazil. Previously, I was a professor at the Federal University of Santa Catarina (UFSC) at the Araranguá campus. I was a member of the Integrated Systems Laboratory (LSI) where my work was related to the design and test  of an ASIC for the Time Projection Chamber of the ALICE experiment in LHC (Large Hadron Collider) - CERN. I have obtained my Doctoral Degree in Microelectronics at the University of São Paulo (USP) in 2015 and the B.Sc. degree in Electrical Engineering at the Federal University of Santa Maria in 2010.</td>
</tr>
</tbody>
</table>
</div>



<div id="outline-container-org20a1766" class="outline-3">
<h3 id="org20a1766">Research Interests</h3>
<div class="outline-text-3" id="text-org20a1766">
<p>
My main research interests are: 
</p>
<ul class="org-ul">
<li>artificial intelligence hardware (mixed-signal hardware accelerators) and analog computing.</li>
<li>CAD tools for analog integrated circuits;</li>
<li>optimization, metaheuristics and artificial intelligence techniques;</li>
<li>data acquisition and instrumentation.</li>
</ul>
</div>
</div>

<div id="outline-container-orgdb3722d" class="outline-3">
<h3 id="orgdb3722d">Goals</h3>
<div class="outline-text-3" id="text-orgdb3722d">
<p>
Our plans for the future are as important as where we are right now. To provide a better insight about my professional goals, I've decided to share my short and long-term objectives. 
</p>

<p>
<i>5-year</i> goal (renewed, from 2022 to 2027): become a leading researcher in <b>artificial intelligence hardware (mixed-signal hardware accelerators for AI applications) applied to sensor-based systems</b>; 
</p>

<p>
<i>10-year</i> goal (renewed, from 2022 to 2032): become an international leading researcher in <b>artificial intelligence hardware</b> applied to sensor-based systems;
</p>
</div>
</div>


<div id="outline-container-org8450d2d" class="outline-3">
<h3 id="org8450d2d">Contact</h3>
<div class="outline-text-3" id="text-org8450d2d">
<ul class="org-ul">
<li>E-mail: tiago.weber (at) ufrgs.br</li>
<li><a href="http://www.researchgate.net/profile/Tiago_Oliveira_Weber">ResearchGate</a></li>
<li><a href="https://br.linkedin.com/in/tiago-oliveira-weber-95aa1b8">LinkedIn</a></li>
<li><a href="https://www.instagram.com/tiagooliveiraweber/">Instagram</a></li>
</ul>
</div>
</div>

<div id="outline-container-org58b2ec2" class="outline-3">
<h3 id="org58b2ec2">Curriculum</h3>
<div class="outline-text-3" id="text-org58b2ec2">
<ul class="org-ul">
<li><a href="http://lattes.cnpq.br/6453626164328516">Lattes</a></li>
</ul>
</div>
</div>




<div id="outline-container-orgb999e81" class="outline-3">
<h3 id="orgb999e81">Education</h3>
<div class="outline-text-3" id="text-orgb999e81">
</div>
<div id="outline-container-org0c8438c" class="outline-4">
<h4 id="org0c8438c">Doctoral Degree in Microelectronics - June 2015</h4>
<div class="outline-text-4" id="text-org0c8438c">
<p>
University of São Paulo - São Paulo, Brazil
</p>

<ul class="org-ul">
<li>Dissertation Title (translated from Portuguese): Synthesis of analog integrated circuits in system-level and circuit-level using modern optimization methods</li>
<li>Research Synopsis: analog integrated circuits are very important in modern electronic systems, performing tasks such as analog to digital conversion, digital to analog conversion, radio frequency communication, filtering and others. The design of this type of circuit requires attending to several performance specifications, being usually performed only by experienced designers. We developed techniques for the design of circuit-level and system-level analog circuits. As the optimization core, we proposed an algorithm based on Simulated Annealing while considering multiobjective information through the use of a crossover operator. An hybrid algorithm combining the proposed algorithm with Particle Swarm Optimization was created to properly explore the Pareto front. Tests indicated the algorithms are efficient for the design of analog circuits as well as outperform many other derivative-free algorithms when applied to purely mathematical problems.</li>
</ul>
</div>
</div>

<div id="outline-container-org1014668" class="outline-4">
<h4 id="org1014668">B.Sc. in Electrical Engineering - Jan. 2010</h4>
<div class="outline-text-4" id="text-org1014668">
<p>
Federal University of Santa Maria - Santa Maria, Brazil
</p>
<ul class="org-ul">
<li>Undergraduate Thesis Title (translated from Portuguese): Tool for integrated circuit synthesis with an educational approach</li>
</ul>

<p>
&#x2013; Modules included:
</p>
<ul class="org-ul">
<li>Analog Integrated Circuits Design</li>
<li>Special Topics in Microelectronics</li>
<li>Programmable Logic Systems</li>
<li>Conception of Integrated Circuits</li>
<li>Data Communication</li>
<li>Signal Processing</li>
</ul>
</div>
</div>
</div>
</div>


<div id="outline-container-org89813b9" class="outline-2">
<h2 id="org89813b9">Research</h2>
<div class="outline-text-2" id="text-org89813b9">
<p>
Here you will find:
</p>
<ul class="org-ul">
<li>My research projects and goals</li>
<li>My publications</li>
</ul>

<p>
I'm currently a member of the IEE-IA lab (<a href="https://www.ufrgs.br/ieelab/index.php">https://www.ufrgs.br/ieelab/index.php</a>).
</p>
</div>

<div id="outline-container-org8ef14d1" class="outline-3">
<h3 id="org8ef14d1">Research Projects and Goals</h3>
<div class="outline-text-3" id="text-org8ef14d1">
<p>
By sharing my research projects and goals, the objective is to communicate my professional road map to current and potential collaborators (other researchers, students and companies). 
</p>
</div>


<div id="outline-container-org5a444af" class="outline-4">
<h4 id="org5a444af">Artificial Intelligence - Hardware Accelerators</h4>
<div class="outline-text-4" id="text-org5a444af">
<p>
<div class="FRAME_WRAPPER">
<div class="FRAME_LEFT">
</p>

<p>
</div>
<div class="FRAME_RIGHT">
</p>

<p>
This research line objective is the development of integrated circuits to provide hardware acceleration for Artificial Intelligence applications. 
Analog and mixed-signal solutions are being studied to improve figures-of-merit on hardware-based machine learning.
</p>

<p>
</div>
<div class="FRAME_BOTTOM">
</p>

<p>
</div> </div> 
</p>
</div>
</div>
<div id="outline-container-org66276ff" class="outline-4">
<h4 id="org66276ff">Microelectronics / Analog Design Synthesis</h4>
<div class="outline-text-4" id="text-org66276ff">
<p>
<div class="FRAME_WRAPPER">
<div class="FRAME_LEFT">
</p>


<p>
</div>
<div class="FRAME_RIGHT">
</p>


<p>
This research line aims at the development of techniques for analog design synthesis in circuit and system level. The objective is to advance the state-of-the art in analog circuit synthesis/optimization by bridging system-level optimization with circuit-level optimization. 
</p>


<p>
</div>
<div class="FRAME_BOTTOM">
</p>

<p>
</div> </div> 
</p>
</div>
</div>
<div id="outline-container-org8562d0f" class="outline-4">
<h4 id="org8562d0f">Artificial Intelligence applied to Instrumentation</h4>
<div class="outline-text-4" id="text-org8562d0f">
<p>
<div class="FRAME_WRAPPER">
<div class="FRAME_LEFT">
</p>


<p>
</div>
<div class="FRAME_RIGHT">
</p>

<p>
This research line objective is the development of new Artificial Intelligence techniques directed at instrumentation applications.
</p>

<p>
</div>
<div class="FRAME_BOTTOM">
</p>

<p>
</div> </div> 
</p>
</div>
</div>
</div>


<div id="outline-container-org2246659" class="outline-3">
<h3 id="org2246659">Publications</h3>
<div class="outline-text-3" id="text-org2246659">
</div>
<div id="outline-container-orgfda3bb2" class="outline-4">
<h4 id="orgfda3bb2">Journal publications (per topic)</h4>
<div class="outline-text-4" id="text-orgfda3bb2">
<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>CABRERA, F. L., WEBER, T. O. A Rail-to-Rail Topology for CMOS Neuron Cells with Analog Inputs-Output and Digital Weights. <i>International Journal of Electronics</i>, DOI: 10.1080/00207217.2021.1969440, 2021. <a href="https://www.tandfonline.com/doi/citedby/10.1080/00207217.2021.1969440?scroll=top&amp;needAccess=true">Link</a></li>

<li>WEBER, T. O., CABRERA, F. L., LABRES, D. da S. Topology Variations of an Amplifier-based MOS Analog Neural Network Implementation and Weights Optimization. <i>Analog Integrated Circuits and Signal Processing</i>,  106(3), 635-647, DOI 10.1007/s10470-021-01798-y, 2021. <a href="http://links.springernature.com/f/a/BKVyWucZb0j7h9H26vOhTQ~~/AABE5gA~/RgRiMxwXP0TtaHR0cDovL2xpbmsuc3ByaW5nZXIuY29tL2FydGljbGUvMTAuMTAwNy9zMTA0NzAtMDIxLTAxNzk4LXk_d3RfbWM9SW50ZXJuYWwuRXZlbnQuMS5TRU0uQXJ0aWNsZUF1dGhvckFzc2lnbmVkVG9Jc3N1ZSZ1dG1fc291cmNlPUFydGljbGVBdXRob3JBc3NpZ25lZFRvSXNzdWUmdXRtX21lZGl1bT1lbWFpbCZ1dG1fY29udGVudD1BQV9lbl8wNjA4MjAxOCZBcnRpY2xlQXV0aG9yQXNzaWduZWRUb0lzc3VlXzIwMjEwMzE3VwNzcGNCCmBLl-hRYBYQ9BpSFHRpYWdvLndlYmVyQHVmcmdzLmJyWAQAAAbn">Link</a></li>
</ul>

<p width="300px image" title="Photo" align="center">
<img src="img/alog2021_topologies.png" alt="alog2021_topologies.png" width="300px image" title="Photo" align="center" />
Neuron topologies. Image from the paper above.
</p>

<p>
</div>
</p>


<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>ROQUE, Felipe, CECHINEL, Cristian, WEBER, T. O., LEMOS, Robson, VILLARROEL, R., MIRANDA, D.; MUNOZ, R. Using Depth Cameras to Detect Patterns in Oral Presentations: A Case Study Comparing Two Generations of Computer Engineering Students. <i>Sensors</i>, DOI 10.3390/s19163493, 2019. <a href="https://www.mdpi.com/1424-8220/19/16/3493">Link</a></li>
</ul>

<p width="300px image" title="Photo" align="center">
<img src="img/body_postures.png" alt="body_postures.png" width="300px image" title="Photo" align="center" />
Setting environment. Image from the paper above.
</p>

<p>
</div>
</p>

<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>ADOLFSSON, J. et al. The upgrade of the ALICE TPC with GEMs and continuous readout, <i>Journal of Instrumentation</i>, v. 16, n. 3, P03022, 2021. <a href="https://iopscience.iop.org/article/10.1088/1748-0221/16/03/P03022">Link</a></li>

<li>HERNANDEZ, H.; SANCHES, B.; CARVALHO, D.; BREGANT, M.; PABON, A. A.; WILTON, R.; HERNANDEZ,  R. A.; WEBER, T. O.; COUTO, A.; LOMBARDI, A.; ALARCON, H.; MARTINS, T. A.; MUNHOZ, M. G.; NOIJE; W. V. A Monolithic 32-channel Front-End and DSP ASIC for Gaseous Detectors. <i>IEEE Transactions on Instrumentation and Measurement</i>, DOI 10.1109/TIM.2019.2931016, 2019. <a href="https://ieeexplore.ieee.org/document/8772086/">Link</a></li>

<li>ADOLFSSON, J.; PABON, A. AYALA; BREGANT, M.; BRITTON, C.; BRULIN, G.; CARVALHO, D.; CHAMBERT, V.; CHINELLATO, D.; ESPAGNON, B.; HERRERA, H.D. HERNANDEZ; LJUBICIC, T.; MAHMOOD, S.M.; MJÖRNMARK, U.; MORAES, D.; MUNHOZ, M.G.; NOËL, G.; OSKARSSON, A.; OSTERMAN, L.; PILYAR, A.; READ, K.; RUETTE, A.; RUSSO, P.; SANCHES, B.C.S.; SEVERO, L.; SILVERMYR, D.; SUIRE, C.; TAMBAVE, G.J.; TUN-LANOË, K.M.M.; NOIJE, W. VAN; VELURE, A.; VERESCHAGIN, S.; WANLIN, E.; WEBER, T.O.; ZAPOROZHETS, S. SAMPA Chip: the New 32 Channels ASIC for the ALICE TPC and MCH Upgrades. <i>Journal of Instrumentation</i>, v.12, p.C04008 - C04008, 2017. <a href="http://iopscience.iop.org/article/10.1088/1748-0221/12/04/C04008">Link</a></li>

<li>BARBOZA, S.H.I. ; BREGANT, M. ; CHAMBERT, V. ; ESPAGNON, B. ; HERRERA, H.D. HERNANDEZ ; MAHMOOD, S.M. ; MORAES, D. ; MUNHOZ, M.G. ; NOËL, G. ; PILYAR, A. ; RUSSO, P. ; SANCHES, B.C.S ; TAMBAVE, G.J. ; TUN-LANOË, K.M.M. ; NOIJE, W. VAN ; VELURE, A. ; VERESCHAGIN, S. ; WEBER, T.O. ; ZAPOROZHETS, S. . SAMPA chip: a new ASIC for the ALICE TPC and MCH upgrades. <i>Journal of Instrumentation</i>, v. 11, p. C02088-C02088, 2016. <a href="http://iopscience.iop.org/article/10.1088/1748-0221/11/02/C02088/meta">Link</a></li>
</ul>

<p width="500px image" title="Photo" align="center">
<img src="img/sampa_board.jpg" alt="sampa_board.jpg" width="500px image" title="Photo" align="center" /> 
SAMPA Chip. Photo: Marcos Santos/USP Imagens 
</p>

<p>
</div>
</p>


<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>WEBER, T.O.; NOIJE, W.A.M.V. Analog Circuit Synthesis Performing Fast Pareto Frontier Exploration and Analysis Through 3D Graphs. <i>Analog Integrated Circuits and Signal Processing</i>, Springer US,  v. 73, n. 3, p. 861-871, ISSN 0925-1030, 2012; <a href="http://link.springer.com/article/10.1007%252Fs10470-012-9939-z">Link</a></li>
</ul>


<div id="org00c8a04" class="figure">
<p><img src="img/pareto_miller.png" alt="pareto_miller.png" width="600px image" title="Photo" align="center" /> 
</p>
</div>

<p>
</div>
</p>

<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>WEBER, T.O.; NOIJE, W.A.M.V. Multi-Objective Design of Analog Integrated Circuits using Simulated Annealing with Crossover Operator and Weight Adjusting. <i>JICS. Journal of Integrated Circuits and Systems</i>, v. 7, n. 1, p. 1-9, ISSN 1807-1953, 2012. <a href="http://www.sbmicro.org.br/jics/html/volume7n1.html">Link</a>, <a href="http://ojs.fei.edu.br/ojs/index.php/JICS/issue/view/20">Link</a>.</li>
</ul>

<p>
</div>
</p>
</div>
</div>


<div id="outline-container-org99f2011" class="outline-4">
<h4 id="org99f2011">Book chapter</h4>
<div class="outline-text-4" id="text-org99f2011">
<p>
<div class="FRAME_WRAPPER_BOARD">
</p>

<ul class="org-ul">
<li>WEBER, T.O.; NOIJE, W.A.M.V. Design of Analog Integrated Circuits using Simulated Annealing/Quenching with Crossovers and Particle Swarm Optimization. <i>Simulated Annealing - Advances, Applications and Hybridizations</i>, v. 1,  p. 219-244, Ed. InTech, ISBN 978-953-51-0710-1, 2012. <a href="http://www.intechopen.com/books/simulated-annealing-advances-applications-and-hybridizations/design-of-analog-integrated-circuits-using-simulated-annealing-quenching-combined-with-population-ba">Link</a></li>
</ul>


<div id="org4033a89" class="figure">
<p><img src="img/sa_crossover_pso.jpg" alt="sa_crossover_pso.jpg" width="500px image" title="Photo" align="center" /> 
</p>
</div>

<p>
</div>
</p>
</div>
</div>

<div id="outline-container-orga0e8956" class="outline-4">
<h4 id="orga0e8956">Conference publications</h4>
<div class="outline-text-4" id="text-orga0e8956">
<ul class="org-ul">
<li>BUSCHETTO, L. A.; ROQUE, F. V.; CASAGRANDE, L.; WEBER, T. O.; CECHINEL C. A Block-Processing Approach Using Texture Analysis for Fabric Defect Detection <i>In: Anais do Computer on the beach</i>, Florianópolis, SC, 2020. <a href="https://doi.org/10.14210/cotb.v11n1.p221-228">Link</a></li>
<li>ROQUE, F.; CECHINEL, C.; MUNÕZ, R.; LEMOS, R.; WEBER, T. O. Encontrando os padrões sequenciais em apresentações orais de estudantes utilizando Sequential Pattern Mining <i>In: Anais do Simpósio Brasileiro de Informática na Educação (SBIE)</i>, 2019. <a href="https://br-ie.org/pub/index.php/sbie/article/view/8923">Link</a></li>
<li>WEBER, T. O.; LABRES, D. S.; CABRERA, F. L. Amplifier-based MOS Analog Neural Network Implementation and Weights Optimization <i>In:  Proceedings of the 32nd Symposium on Integrated Circuits and Systems Design (SBCCI)</i>, 2019, São Paulo, SP. <a href="https://dl.acm.org/citation.cfm?id=3339866">Link</a> <b>(won SBCCI Best Paper Award)</b></li>
<li>ROQUE, F. V.; MACARINI, L. A.; CROTTI, Y.; WEBER, T. O., CECHINEL, C. Detecção de defeitos visuais em tecidos utilizando Wavelets e algoritmos de aprendizado de máquina <i>In: Anais do Computer on the beach</i>, 2019, Florianópolis, SC. <a href="https://siaiap32.univali.br/seer/index.php/acotb/article/view/14359">Link</a></li>
<li>MARTINS, J. F.; WEBER, T. O. Sistema Matricial de Interconexão Programável para Aplicação em Laboratórios Remotos de Eletrônica Analógica <i>In: Anais do 7º Simpósio de Integração Científica e Tecnológica do Sul Catarinense (SICT-SUL)</i>, 2018, Araranguá, SC. <a href="http://criciuma.ifsc.edu.br/anais-sict-sul/">Link</a></li>
<li>MARTINS, J. F.; WEBER, T. O. Matriz de Interconexão Eletrônica Programável de Baixo Custo para Aplicação em Laboratório Remoto e Prototipagem Rápida <i>In: Anais do Simpósio Ibero-Americano de Tecnologias Educacionais (SITED)</i>, 2018, Araranguá, SC.</li>
<li>MACARINI, L. A.; WEBER, T. O. Quality Control System for Ceramic Tiles using Segmentation-based Fractal Texture Analysis and SVM <i>In: CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES, 30. (SIBGRAPI)</i>, 2017, Niterói, RJ. <a href="http://urlib.net/8JMKD3MGPAW/3PH2NFL">Link</a></li>
</ul>

<ul class="org-ul">
<li>WEBER, T.O.; CHAPARRO, S.; NOIJE, W.A.M.V. Synthesis of a Narrow-band Low Noise Amplifier in a 180 nm CMOS Technology using Simulated Annealing with Crossover Operator. <i>In: Proceedings of the 26th Symposium on Integrated Circuits and Systems</i> p. 1-5, Curitiba, Brasil, 2013. <a href="https://doi.org/10.1109/SBCCI.2013.6644878">Link</a></li>
<li>WEBER, T.O.; NOIJE, W.A.M.V. Analog Design Synthesis Performing Fast Pareto Frontier Exploration. <i>In: Proceedings of the 2nd IEEE Latin American Symposium on Circuits and Systems</i>,  p. 62-66, ISBN 978-1-4244-9484-2, Bogotá, Colômbia, 2011; <a href="https://doi.org/10.1109/LASCAS.2011.5750289">Link</a></li>
<li>WEBER, T.O.; NOIJE, W.A.M.V. Analog Design Synthesis Method Using Simulated Annealing and Particle Swarm Optimization. <i>In: Proceedings of the 24th Symposium on Integrated Circuits and Systems</i>, p. 85-90, ISBN 978-1-4503-0828-1, João Pessoa, Brasil, 2011. <a href="https://doi.org/10.1145/2020876.2020897">Link</a></li>
</ul>

<ul class="org-ul">
<li>WEBER, T.O.; RODRIGUES, C. R. Automatic LC Oscillator Systematic Design using Matlab and SPICE Interaction <i>Iberchip Workshop, XV</i>, Buenos Aires - Argentina, March 2009</li>
</ul>

<ul class="org-ul">
<li>HAYASAKA, H.; WEBER, T. O.; RODRIGUES, C. R. Oscilador LC à 2,4GHz Controlado por Tensão em Tecnologia AMI 05 <i>Jornadas de Jóvenes Investigadores</i>, XVI, Montevideo - Uruguay, October 2008</li>
</ul>
</div>
</div>
</div>
</div>


<div id="outline-container-orgfd2e902" class="outline-2">
<h2 id="orgfd2e902">Teaching and Academic Advisory</h2>
<div class="outline-text-2" id="text-orgfd2e902">
</div>
<div id="outline-container-org5f5cb05" class="outline-3">
<h3 id="org5f5cb05">Classes at the <a href="http://www.ufrgs.br/english/home">Federal University of Rio Grande do Sul (UFRGS)</a></h3>
<div class="outline-text-3" id="text-org5f5cb05">
<p>
My lectures at UFRGS are mainly to the <a href="https://www.ufrgs.br/engele/en/overview/">Electrical Engineering course</a>.
</p>

<ul class="org-ul">
<li>Second semester of 2020:
<ul class="org-ul">
<li>Instrumentation A (in Portuguese: "Instrumentação A"): theoretical and laboratory classes. Due to the Covid-19 pandemic, laboratory classes were replaced by simulations and intelligent instrumentation computational experiments.</li>
</ul></li>

<li>First semester of 2020:
<ul class="org-ul">
<li>Instrumentation A - laboratory classes (in Portuguese: "Instrumentação A"). Due to the Covid-19 pandemic, laboratory classes were replaced by simulations and intelligent instrumentation computational experiments.</li>
<li>Special Topics in Instrumentation I (in Portuguese: "Tópicos Especiais em Instrumentação I"): class related to computational intelligence</li>
</ul></li>
</ul>

<ul class="org-ul">
<li>Second semester of 2019 (second half):
<ul class="org-ul">
<li>Instrumentation A - laboratory classes (in Portuguese: "Instrumentação A")</li>
<li>Electricity - (in Portuguese: "Eletricidade"): class taught to the Mechanical Engineering course</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org46bfb44" class="outline-3">
<h3 id="org46bfb44">Classes at the <a href="http://en.ufsc.br/">Federal University of Santa Catarina (UFSC)</a></h3>
<div class="outline-text-3" id="text-org46bfb44">
<p>
My lectures at UFSC were to the <a href="http://enc.ufsc.br/">Computer Engineering course</a>:
</p>

<ul class="org-ul">
<li>Second semester of 2019 (first half):
<ul class="org-ul">
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
<li>Special Topics in Analog Electronics (in Portuguese: "Tópicos Especiais em Eletrônica Analógica")</li>
<li>Data Communication (in Portuguese: "Comunicação de Dados")</li>
</ul></li>
<li>First semester of 2019:
<ul class="org-ul">
<li>Electric Circuits for Computer Engineering (in Portuguese: "Circuitos Elétricos para Computação")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>Second semester of 2018:
<ul class="org-ul">
<li>Electric Circuits for Computer Engineering (in Portuguese: "Circuitos Elétricos para Computação")</li>
<li>Data Communication (in Portuguese: "Comunicação de Dados")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>First semester of 2018:
<ul class="org-ul">
<li>Data Communication (in Portuguese: "Comunicação de Dados")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>Second semester of 2017:
<ul class="org-ul">
<li>Special Topics in Analog Microelectronics (in Portuguese: "Tópicos Especiais em Microeletrônica Analógica")</li>
<li>Data Communication (in Portuguese: "Comunicação de Dados")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>First semester of 2017:
<ul class="org-ul">
<li>Special Topics in Analog Microelectronics (in Portuguese: "Tópicos Especiais em Microeletrônica Analógica")</li>
<li>Electric Circuits for Computer Engineering (in Portuguese: "Circuitos Elétricos para Computação")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>Second semester of 2016:
<ul class="org-ul">
<li>Electric Circuits for Computer Engineering (in Portuguese: "Circuitos Elétricos para Computação")</li>
<li>Data Communication (in Portuguese: "Comunicação de Dados")</li>
<li>Signal Acquisition Systems (in Portuguese: "Sistemas de Aquisição de Sinais")</li>
</ul></li>
<li>First semester of 2016:  
<ul class="org-ul">
<li>Electric Circuits for Computer Engineering (in Portuguese: "Circuitos Elétricos para Computação")</li>
<li>Fundamentals of Mathematics to Computer Science (in Portuguese: "Fundamentos Matemáticos para Computação")</li>
</ul></li>
</ul>
</div>
</div>


<div id="outline-container-org37988f2" class="outline-3">
<h3 id="org37988f2">Honors</h3>
<div class="outline-text-3" id="text-org37988f2">
</div>
<div id="outline-container-org7f693d2" class="outline-4">
<h4 id="org7f693d2">related to my teaching activity at UFRGS</h4>
<div class="outline-text-4" id="text-org7f693d2">
<ul class="org-ul">
<li>Professor homenageado da turma 2021/1 de Engenharia Elétrica da Universidade Federal do Rio Grande do Sul (UFRGS);</li>
<li>Prêmio Destaque Docente no aniversário de 125 anos da Escola de Engenharia da UFRGS.</li>
</ul>
</div>
</div>

<div id="outline-container-org294734e" class="outline-4">
<h4 id="org294734e">related to my teaching activity at UFSC</h4>
<div class="outline-text-4" id="text-org294734e">
<ul class="org-ul">
<li>Patrono da turma 2021/1 de Engenharia de Computação da Universidade Federal de Santa Catarina (UFSC), campus Araranguá;</li>
<li>Patrono da turma 2020/1 de Engenharia de Computação da Universidade Federal de Santa Catarina (UFSC), campus Araranguá;</li>
<li>Professor homenageado da turma de Engenharia de Computação - Turma 2019/2.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9ed72d5" class="outline-3">
<h3 id="org9ed72d5">Short Course</h3>
<div class="outline-text-3" id="text-org9ed72d5">
<ul class="org-ul">
<li>Course in GNU Octave / Matlab and Applications for Engineers (in Portuguese: "Curso de GNU Octave / Matlab e Aplicações para Engenheiros"). This material was presented at the II Computer Engineering Academic Week in March 2018 at UFSC - Campus Araranguá - <a href="data/courses/octave_matlab_course_tweber_v1.pdf">Presentation in Portuguese</a></li>
</ul>
</div>
</div>



<div id="outline-container-org8226aec" class="outline-3">
<h3 id="org8226aec">Academic Advisory</h3>
<div class="outline-text-3" id="text-org8226aec">
<ul class="org-ul">
<li>Lucas Raupp Hans. <i>Sistema de classificação de tipos de movimentos no esporte tênis utilizando sensores inerciais e técnicas de aprendizado de máquina supervisionado</i>. 2022. Trabalho de Conclusão de Curso. (Graduação em Engenharia Elétrica) - Universidade Federal do Rio Grande do Sul. Orientador: Tiago Oliveira Weber. <a href="http://hdl.handle.net/10183/245912">Link</a></li>

<li>Lucas Henz Garcia. <i>Detecção de emoções utilizando redes neurais convolucionais em sistemas com recursos limitados de hardware</i>. 2021. Trabalho de Conclusão de Curso. (Graduação em Engenharia Elétrica) - Universidade Federal do Rio Grande do Sul. Orientador: Tiago Oliveira Weber. <a href="http://hdl.handle.net/10183/234173">Link</a></li>

<li>Thiago Matias Martins. <i>Aplicação de Técnicas de Inteligência Artificial na Detecção do Comportamento Tipo-Depressivo em Camundongos através do Teste de Suspensão pela Cauda</i>. 2018. Trabalho de Conclusão de Curso. (Graduação em Engenharia de Computação) - Universidade Federal de Santa Catarina. Orientador: Tiago Oliveira Weber. <a href="https://repositorio.ufsc.br/handle/123456789/192344">Link</a></li>

<li>Leonardo Loch da Silva. <i>Sistema de monitoramento de energia elétrica utilizando o protocolo de comunicação MQTT</i>. 2018. Trabalho de Conclusão de Curso. (Graduação em Engenharia de Computação) - Universidade Federal de Santa Catarina. Orientador: Tiago Oliveira Weber. <a href="https://repositorio.ufsc.br/handle/123456789/192296">Link</a></li>

<li>Julyan Figueredo Martins. <i>Matriz de Interconexão Eletrônica Programável para Prototipagem Rápida e Experimentação Remota</i>. 2018. Trabalho de Conclusão de Curso. (Graduação em Engenharia de Computação) - Universidade Federal de Santa Catarina. Orientador: Tiago Oliveira Weber. <a href="https://repositorio.ufsc.br/handle/123456789/192192">Link</a></li>

<li>Felipe Vieira Roque. <i>Sistema de detecção de defeitos em tecidos utilizando algoritmos de classificação e wavelets</i>. 2017. Trabalho de Conclusão de Curso. (Graduação em Engenharia de Computação) - Universidade Federal de Santa Catarina. Orientador: Tiago Oliveira Weber. <a href="https://repositorio.ufsc.br/handle/123456789/182275">Link</a></li>

<li>Luiz Antonio Buschetto Macarini. <i>Sistema de detecção de defeitos em pisos cerâmicos baseado em processamento de imagens e aprendizado de máquina</i>. 2017. Trabalho de Conclusão de Curso. (Graduação em Engenharia de Computação) - Universidade Federal de Santa Catarina. Orientador: Tiago Oliveira Weber. <a href="https://repositorio.ufsc.br/handle/123456789/182175">Link</a></li>
</ul>
</div>
</div>
</div>



<div id="outline-container-blog" class="outline-2">
<h2 id="blog">Blog</h2>
<div class="outline-text-2" id="text-blog">
<p>
<a href="http://tiagoweber.github.io/blog.xml" style="float: right;" title="Subscribe to my feed"><img src="/feed-icon.gif" style="border:0"/></a><br>
</p>

<p>
<a href="http://tiagoweber.github.io/index.html#blog">Back home</a>  <a href="http://tiagoweber.github.io/blog.xml" style="float: right;" title="Subscribe to my feed"><img src="../feed-icon.gif" style="border:0"/></a><br>
</p>
</div>

<div id="outline-container-org365303d" class="outline-3">
<h3 id="org365303d"><a href="./blog/entry4.html"> Integrate your Circuit Design Flow and Reports: Demonstration of Ngspice and Octave/Matlab Interaction within Emacs</a></h3>
<div class="outline-text-3" id="text-org365303d">
<p>
by Tiago Oliveira Weber <span class="timestamp-wrapper"><span class="timestamp">&lt;04/08/2016-qui&gt;</span></span>
</p>


<p>
Can you imagine being able to explore new design ideas, perform calculations, run circuit simulations, calculate some more based on the results and generate reports, all in the same place? Well, you can stop imagining and start developing your next electric/electronic project on Emacs. 
</p>

<p>
Recently, I've made a <a href="./entry1.html">blog post</a> introducing <a href="attachments/ob-spice.el">ob-spice</a>, which is a simple language extension to ob-babel to be able to simulate Ngspice within Emacs. In the present post I will show how we can use ob-spice to perform interaction between Ngspice, Octave (or Matlab) and any other language of our interest. While the experienced org-mode user would already assume this interaction possible from ob-babel features, it is the first demonstration of ob-spice receiving vector inputs (a new feature to ob-spice) and producing outputs back to other languages.
</p>

<p>
In our example we will design a simple opamp inverting topology. For that purpose, we will calculate the resistor values in Octave/Matlab, pass the values to  <a href="././blog/entry4.html">&#x2026; Read more</a>
</p>

<p>
<a href="http://tiagoweber.github.io/index.html#blog">Back home</a>  <a href="http://tiagoweber.github.io/blog.xml" style="float: right;" title="Subscribe to my feed"><img src="../feed-icon.gif" style="border:0"/></a><br>
</p>
</div>
</div>

<div id="outline-container-org42aa1db" class="outline-3">
<h3 id="org42aa1db"><a href="./blog/entry3.html"> Design Automation Conferece (DAC) Video About Moving EDA Tools to Open Source</a></h3>
<div class="outline-text-3" id="text-org42aa1db">
<p>
by Tiago Oliveira Weber <span class="timestamp-wrapper"><span class="timestamp">&lt;06/07/2016-qua&gt;</span></span>
</p>

<p>
The <a href="https://dac.com/events">53rd Design Automation Conference</a> had a great discussion about opportunities for open source tools on the Electronic Design Automation world and market models for existing companies. Luckily for all of us, the panel video is available online on YouTube's <a href="https://www.youtube.com/watch?v=5WmYtyBeuQY">DAC TV channel</a> with the title "Lanza’s Tech Vision Challenge: Daring to Move to Open Source". The moderator was Lucio Lanza (from Lanza TechVentures) and the panelists were Warran Savage (from IP Extreme), Mark Templeton (from Scientific Ventures) and Michael Wishart (from eFabless).
</p>

<p>
In my opinion all participants were very rational on their statements although having different points of view. I, as an open source advocate, felt very glad this type of discussion is taking place in such a relevant conference and with people that know from the inside out how the current EDA business works.
 <a href="././blog/entry3.html">&#x2026; Read more</a>
</p>

<p>
<a href="http://tiagoweber.github.io/index.html#blog">Back home</a>   <a href="http://tiagoweber.github.io/blog.xml" style="float: right;" title="Subscribe to my feed"><img src="../feed-icon.gif" style="border:0"/></a><br>
</p>
</div>
</div>

<div id="outline-container-org9eab3e4" class="outline-3">
<h3 id="org9eab3e4"><a href="./blog/entry2.html"> Software/Hardware Integration Lab</a></h3>
<div class="outline-text-3" id="text-org9eab3e4">
<p>
by Tiago Oliveira Weber <span class="timestamp-wrapper"><span class="timestamp">&lt;27/06/2016-seg&gt;</span></span>
</p>

<p>
I am now a member of the <b>Software/Hardware Integration Lab</b> (<a href="https://lisha.ufsc.br/HomePage">LISHA</a>) at the Federal University of Santa Catarina. According to the official site:
</p>

<p>
The Software/Hardware Integration Lab (LISHA) was founded in 1985 to promote research in the frontiers between hardware and software. Since then, it has dedicated considerable efforts to research in areas such as computer architecture, operating systems, computer networks and the related applications. Currently, the laboratory focuses on innovative techniques and tools to support the development of embedded systems.
</p>

<p>
My webpage at LISHA is <a href="https://lisha.ufsc.br/Weber">https://lisha.ufsc.br/Weber</a> and the announcement (in portuguese) of the start of LISHA at UFSC Araranguá is <a href="http://enc.ufsc.br/2016/06/27/laboratorio-de-integracao-de-software-e-hardware-da-ufsc-tem-agora-unidade-no-campus-ararangua/">here</a>.
 <a href="././blog/entry2.html">&#x2026; Read more</a>
</p>

<p>
<a href="http://tiagoweber.github.io/index.html#blog">Back home</a>   <a href="http://tiagoweber.github.io/blog.xml" style="float: right;" title="Subscribe to my feed"><img src="../feed-icon.gif" style="border:0"/></a><br>
</p>
</div>
</div>

<div id="outline-container-org7016251" class="outline-3">
<h3 id="org7016251"><a href="./blog/entry1.html"> Simulating Circuits with Emacs, Org-mode, Babel and Ngspice</a></h3>
<div class="outline-text-3" id="text-org7016251">
<p>
by Tiago Oliveira Weber <span class="timestamp-wrapper"><span class="timestamp">&lt;26/06/2016-dom&gt;</span></span>
</p>




<p>
Picture this. You are creating a report, studying or preparing a class. While you write your text, you suddenly feel that it is time to show in a circuit how your project works. Now the adventure begins: to add the results of a given simulation to your document, you will have to open your simulation software in another window, describe the circuit using a schematic editor, simulate it and then copy and paste the results to your text file. You might as well copy the image of some waveforms. Additionaly, you will also have to describe the circuit elements in such a way that the reader of your report knows what you have simulated. 
</p>

<p>
In this process a lot can be lost: the quality of your schematic screenshots may or may not be a delight to the eyes, but even if the quality is great, there is still a lot of information that is not accessible through an image of the schematic. These can be the various component properties, simulation parameters and component models. In top of that, if you are like me, you will probably spend a lot of time editing and working with the waveforms to make them fit <a href="././blog/entry1.html">&#x2026; Read more</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org4cc94cd" class="outline-2">
<h2 id="org4cc94cd">Microelectronics</h2>
<div class="outline-text-2" id="text-org4cc94cd">
</div>
<div id="outline-container-orgccfccd8" class="outline-3">
<h3 id="orgccfccd8">Map of Microelectronics in Brazil</h3>
<div class="outline-text-3" id="text-orgccfccd8">
<p>
This map is an attempt to help the visualization of microelectronics in Brazil. Special thanks to Andre Couto and Luciana Shiroma for supplying inicial information about the private companies.
</p>

<iframe width="550" height="400" frameborder="0" src="https://widgets.scribblemaps.com/myl/?d&z&l&gc&af&mc&lat=-17.229332495224924&lng=-47.42284669999998&vz=3&type=road&ti&s&width=550&height=400&id=XN0bwOGANG" style="border:0; max-width: 100%;" allowfullscreen allow="geolocation"></iframe>
</div>

<div id="outline-container-orgeed7641" class="outline-4">
<h4 id="orgeed7641">List</h4>
<div class="outline-text-4" id="text-orgeed7641">
<iframe src="https://docs.google.com/spreadsheets/d/1cITi7SfyIErCCMjsERpNXjgOsw7JBm_wfuCWmnyG6t0/pubhtml?gid=560775876&amp;single=true&amp;widget=true&amp;headers=false"></iframe>
</div>
</div>
</div>
</div>


<div id="outline-container-org8a7fbe6" class="outline-2">
<h2 id="org8a7fbe6">Journal links</h2>
<div class="outline-text-2" id="text-org8a7fbe6">
<p>
This is a list of some relevant journals in my fields of interest. 
</p>

<p>
The classification (A1, A2, B1,&#x2026;) next to the journal name or section is extracted from the Qualis system (used to evaluate scientific production in graduation programs in Brazil - <a href="https://sucupira.capes.gov.br/sucupira/public/consultas/coleta/veiculoPublicacaoQualis/listaConsultaGeralPeriodicos.jsf">link</a>).
</p>
</div>

<div id="outline-container-org41d7d91" class="outline-4">
<h4 id="org41d7d91">Related to Electronics and Microelectronics</h4>
<div class="outline-text-4" id="text-org41d7d91">
<ul class="org-ul">
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8919">IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS. I, REGULAR PAPERS</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=43">IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=71">IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=3468">IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS. PART A. SYSTEMS AND HUMANS</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=92">IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS</a> - A1</li>
<li><a href="https://www.iospress.nl/journal/integrated-computer-aided-engineering/">INTEGRATED COMPUTER-AIDED ENGINEERING</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/signal-processing">SIGNAL PROCESSING</a> - A1</li>
<li><a href="https://link.springer.com/journal/10825">JOURNAL OF COMPUTATIONAL ELECTRONICS</a> - A2</li>
</ul>
</div>
</div>
<div id="outline-container-org3b6ba6e" class="outline-4">
<h4 id="org3b6ba6e">Related to Instrumentation</h4>
<div class="outline-text-4" id="text-org3b6ba6e">
<ul class="org-ul">
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19">IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</a> - A1</li>
<li><a href="https://www.mdpi.com/journal/sensors">SENSORS (BASEL)</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361">IEEE SENSORS JOURNAL</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/sensors-and-actuators-a-physical">SENSORS AND ACTUATORS A: Physical</a> - A1</li>
<li><a href="https://iopscience.iop.org/journal/1748-0221">JOURNAL OF INSTRUMENTATION</a> - A2</li>
</ul>
</div>
</div>

<div id="outline-container-org0d69504" class="outline-4">
<h4 id="org0d69504">Related to Machine Learning and Optimization</h4>
<div class="outline-text-4" id="text-org0d69504">
<ul class="org-ul">
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4235">IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/international-journal-of-approximate-reasoning">INTERNATIONAL JOURNAL OF APPROXIMATE REASONING</a> - A1</li>
<li><a href="https://www.springer.com/mathematics/journal/10957">JOURNAL OF OPTIMIZATION THEORY AND APPLICATIONS</a> - A1</li>
<li><a href="https://link.springer.com/journal/41274">JOURNAL OF THE OPERATIONAL RESEARCH SOCIETY</a> - A1</li>
<li><a href="https://link.springer.com/journal/10994">MACHINE LEARNING</a> - A1</li>
<li><a href="https://www.mitpressjournals.org/loi/neco">NEURAL COMPUTATION</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/neural-networks">NEURAL NETWORKS</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/neurocomputing">NEUROCOMPUTING (AMSTERDAM)</a> - A1</li>
<li><a href="https://www.siam.org/publications/journals/siam-journal-on-optimization-siopt">SIAM JOURNAL ON OPTIMIZATION</a> - A1</li>
<li><a href="https://www.journals.elsevier.com/swarm-and-evolutionary-computation">SWARM AND EVOLUTIONARY COMPUTATION</a> - A1</li>
<li><a href="https://www.jair.org/index.php/jair">THE JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH</a> - A1</li>
</ul>
</div>
</div>

<div id="outline-container-org7d0e6bf" class="outline-4">
<h4 id="org7d0e6bf">Related to Education and Engineering</h4>
<div class="outline-text-4" id="text-org7d0e6bf">
<ul class="org-ul">
<li><a href="https://www.journals.elsevier.com/computers-and-education">COMPUTERS AND EDUCATION</a> - A1</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=13">IEEE TRANSACTIONS ON EDUCATION</a> - A2</li>
<li><a href="https://www.igi-global.com/journal/international-journal-distance-education-technologies/1078">INTERNATIONAL JOURNAL OF DISTANCE EDUCATION TECHNOLOGIES</a> - B1</li>
<li><a href="https://onlinelibrary.wiley.com/journal/10990542">COMPUTER APPLICATIONS IN ENGINEERING EDUCATION</a> - B1</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org93c6889" class="outline-2">
<h2 id="org93c6889">Links for students</h2>
<div class="outline-text-2" id="text-org93c6889">
</div>
<div id="outline-container-org9325e48" class="outline-3">
<h3 id="org9325e48">For students enrolled in "Special Topics in Instrumentation II" (Tópicos Especiais em Instrumentação II)</h3>
<div class="outline-text-3" id="text-org9325e48">
</div>
<div id="outline-container-orgeb00894" class="outline-4">
<h4 id="orgeb00894">Use of EMLearn to export Python code to C</h4>
<div class="outline-text-4" id="text-orgeb00894">
<div class="org-src-container">
<pre class="src src-python" id="org3da4a55"><span style="color: #0000FF;">import</span> os
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> sklearn <span style="color: #0000FF;">import</span> datasets
<span style="color: #0000FF;">from</span> sklearn.model_selection <span style="color: #0000FF;">import</span> train_test_split
<span style="color: #0000FF;">from</span> sklearn.preprocessing <span style="color: #0000FF;">import</span> OneHotEncoder, MinMaxScaler, StandardScaler

<span style="color: #0000FF;">from</span> keras.models <span style="color: #0000FF;">import</span> Sequential
<span style="color: #0000FF;">from</span> keras.layers <span style="color: #0000FF;">import</span> Dense


<span style="color: #BA36A5;">data</span> = datasets.load_iris()

<span style="color: #BA36A5;">X</span> = data[<span style="color: #008000;">'data'</span>]
<span style="color: #BA36A5;">Y</span> = data[<span style="color: #008000;">'target'</span>]

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">use and the scaled input the encoded output</span>
<span style="color: #BA36A5;">enc</span> = OneHotEncoder()
<span style="color: #BA36A5;">Y_enc</span> = enc.fit_transform(Y[:, np.newaxis]).toarray()
<span style="color: #BA36A5;">Y</span> = Y_enc

<span style="color: #BA36A5;">scaler</span> = MinMaxScaler()
<span style="color: #BA36A5;">X_scaled</span> = scaler.fit_transform(X)
<span style="color: #BA36A5;">X</span> = X_scaled

<span style="color: #BA36A5;">X_train</span>, <span style="color: #BA36A5;">X_test</span>, <span style="color: #BA36A5;">Y_train</span>, <span style="color: #BA36A5;">Y_test</span> = train_test_split(X, Y, test_size=0.3, random_state=0)

<span style="color: #BA36A5;">num_features</span> = X.shape[1]
<span style="color: #BA36A5;">num_classes</span> = Y.shape[1]

<span style="color: #BA36A5;">batch_size</span> = 1
<span style="color: #BA36A5;">epochs</span> = 100


<span style="color: #BA36A5;">model</span> = Sequential()
model.add(Dense(5, input_dim=num_features, activation=<span style="color: #008000;">'tanh'</span>))
model.add(Dense(num_classes, activation=<span style="color: #008000;">'softmax'</span>))
model.summary()

model.<span style="color: #006FE0;">compile</span>(loss=<span style="color: #008000;">'categorical_crossentropy'</span>, optimizer=<span style="color: #008000;">'adam'</span>, metrics=[<span style="color: #008000;">'accuracy'</span>])

<span style="color: #BA36A5;">history</span> = model.fit(X_train, Y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    )

<span style="color: #BA36A5;">score_train</span> = model.evaluate(X_train, Y_train, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train loss:'</span>, score_train[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train accuracy:'</span>, score_train[1])

<span style="color: #BA36A5;">score_test</span> = model.evaluate(X_test, Y_test, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test loss:'</span>, score_test[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test accuracy:'</span>, score_test[1])


<span style="color: #0000FF;">import</span> emlearn
<span style="color: #BA36A5;">cmodel</span> = emlearn.net.convert_keras(model, method=<span style="color: #008000;">'loadable'</span>) <span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">methods = pymodule or loadable</span>
cmodel.save(<span style="color: #006FE0;">file</span>=<span style="color: #008000;">'iris_keras.h'</span>, name=<span style="color: #008000;">'iris'</span>)

</pre>
</div>

<pre class="example" id="org7f272f7">
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 5)                 25        
                                                                 
 dense_1 (Dense)             (None, 3)                 18        
                                                                 
=================================================================
Total params: 43
Trainable params: 43
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/105 [..............................] - ETA: 52s - loss: 1.1921 - accuracy: 0.0000e+00 37/105 [=========&gt;....................] - ETA: 0s - loss: 1.1651 - accuracy: 0.1622      69/105 [==================&gt;...........] - ETA: 0s - loss: 1.1311 - accuracy: 0.2609103/105 [============================&gt;.] - ETA: 0s - loss: 1.1164 - accuracy: 0.2913105/105 [==============================] - 1s 2ms/step - loss: 1.1160 - accuracy: 0.2857
Epoch 2/100
  1/105 [..............................] - ETA: 0s - loss: 0.9139 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 1.0431 - accuracy: 0.4474 74/105 [====================&gt;.........] - ETA: 0s - loss: 1.0448 - accuracy: 0.3919105/105 [==============================] - 0s 1ms/step - loss: 1.0366 - accuracy: 0.3714
Epoch 3/100
  1/105 [..............................] - ETA: 0s - loss: 0.9017 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.9886 - accuracy: 0.4167 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.9787 - accuracy: 0.4444105/105 [==============================] - 0s 1ms/step - loss: 0.9695 - accuracy: 0.4952
Epoch 4/100
  1/105 [..............................] - ETA: 0s - loss: 1.1180 - accuracy: 0.0000e+00 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.9056 - accuracy: 0.7027     72/105 [===================&gt;..........] - ETA: 0s - loss: 0.9158 - accuracy: 0.6528105/105 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 0.6762
Epoch 5/100
  1/105 [..............................] - ETA: 0s - loss: 0.7200 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.8658 - accuracy: 0.7222 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.8500 - accuracy: 0.7286105/105 [==============================] - ETA: 0s - loss: 0.8507 - accuracy: 0.6952105/105 [==============================] - 0s 1ms/step - loss: 0.8507 - accuracy: 0.6952
Epoch 6/100
  1/105 [..............................] - ETA: 0s - loss: 0.8180 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.8076 - accuracy: 0.7143 64/105 [=================&gt;............] - ETA: 0s - loss: 0.7848 - accuracy: 0.7656 94/105 [=========================&gt;....] - ETA: 0s - loss: 0.7958 - accuracy: 0.7128105/105 [==============================] - 0s 2ms/step - loss: 0.7962 - accuracy: 0.6952
Epoch 7/100
  1/105 [..............................] - ETA: 0s - loss: 1.0470 - accuracy: 0.0000e+00 31/105 [=======&gt;......................] - ETA: 0s - loss: 0.8415 - accuracy: 0.4839     63/105 [=================&gt;............] - ETA: 0s - loss: 0.7663 - accuracy: 0.6825 97/105 [==========================&gt;...] - ETA: 0s - loss: 0.7519 - accuracy: 0.6804105/105 [==============================] - 0s 2ms/step - loss: 0.7468 - accuracy: 0.6952
Epoch 8/100
  1/105 [..............................] - ETA: 0s - loss: 0.6160 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.7240 - accuracy: 0.6765 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.7104 - accuracy: 0.6812104/105 [============================&gt;.] - ETA: 0s - loss: 0.7020 - accuracy: 0.6923105/105 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.6952
Epoch 9/100
  1/105 [..............................] - ETA: 0s - loss: 0.6345 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.6455 - accuracy: 0.7778 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.6453 - accuracy: 0.7324105/105 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6952
Epoch 10/100
  1/105 [..............................] - ETA: 0s - loss: 1.0095 - accuracy: 0.0000e+00 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.5811 - accuracy: 0.8056     70/105 [===================&gt;..........] - ETA: 0s - loss: 0.6018 - accuracy: 0.7286105/105 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6952
Epoch 11/100
  1/105 [..............................] - ETA: 0s - loss: 0.3486 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.6357 - accuracy: 0.6667 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.6032 - accuracy: 0.6812103/105 [============================&gt;.] - ETA: 0s - loss: 0.5938 - accuracy: 0.6893105/105 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6952
Epoch 12/100
  1/105 [..............................] - ETA: 0s - loss: 0.2265 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.5384 - accuracy: 0.7568 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.5704 - accuracy: 0.6986105/105 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.6952
Epoch 13/100
  1/105 [..............................] - ETA: 0s - loss: 0.2673 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7273 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.5305 - accuracy: 0.7143105/105 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.6952
Epoch 14/100
  1/105 [..............................] - ETA: 0s - loss: 0.1351 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.4897 - accuracy: 0.6757 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.5278 - accuracy: 0.6892105/105 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.6952
Epoch 15/100
  1/105 [..............................] - ETA: 0s - loss: 0.5169 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.5269 - accuracy: 0.7368 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.4935 - accuracy: 0.7397105/105 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.6952
Epoch 16/100
  1/105 [..............................] - ETA: 0s - loss: 0.0882 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.4645 - accuracy: 0.7647 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.4894 - accuracy: 0.7222105/105 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7143
Epoch 17/100
  1/105 [..............................] - ETA: 0s - loss: 0.1123 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.5176 - accuracy: 0.6923 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.5261 - accuracy: 0.6986105/105 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7143
Epoch 18/100
  1/105 [..............................] - ETA: 0s - loss: 0.4267 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.4800 - accuracy: 0.7179 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.4693 - accuracy: 0.7297105/105 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7238
Epoch 19/100
  1/105 [..............................] - ETA: 0s - loss: 0.9036 - accuracy: 0.0000e+00 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.4643 - accuracy: 0.7500     70/105 [===================&gt;..........] - ETA: 0s - loss: 0.4700 - accuracy: 0.7000105/105 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7238
Epoch 20/100
  1/105 [..............................] - ETA: 0s - loss: 0.5151 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7368 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.4602 - accuracy: 0.7397105/105 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7333
Epoch 21/100
  1/105 [..............................] - ETA: 0s - loss: 0.0544 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.4607 - accuracy: 0.8056 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.4232 - accuracy: 0.7808105/105 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7524
Epoch 22/100
  1/105 [..............................] - ETA: 0s - loss: 0.8646 - accuracy: 0.0000e+00 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.4920 - accuracy: 0.6944     72/105 [===================&gt;..........] - ETA: 0s - loss: 0.4295 - accuracy: 0.7778105/105 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7619
Epoch 23/100
  1/105 [..............................] - ETA: 0s - loss: 0.8212 - accuracy: 0.0000e+00 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.4076 - accuracy: 0.7879     68/105 [==================&gt;...........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7647 95/105 [==========================&gt;...] - ETA: 0s - loss: 0.4408 - accuracy: 0.7684105/105 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7619
Epoch 24/100
  1/105 [..............................] - ETA: 0s - loss: 0.7615 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.4514 - accuracy: 0.7941 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8028105/105 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8000
Epoch 25/100
  1/105 [..............................] - ETA: 0s - loss: 0.0179 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.4835 - accuracy: 0.7179 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.4265 - accuracy: 0.7973105/105 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8190
Epoch 26/100
  1/105 [..............................] - ETA: 0s - loss: 0.8467 - accuracy: 0.0000e+00 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.4348 - accuracy: 0.8056     74/105 [====================&gt;.........] - ETA: 0s - loss: 0.4276 - accuracy: 0.7838105/105 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8095
Epoch 27/100
  1/105 [..............................] - ETA: 0s - loss: 0.4174 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.3647 - accuracy: 0.8421 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.4153 - accuracy: 0.7973105/105 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8190
Epoch 28/100
  1/105 [..............................] - ETA: 0s - loss: 0.6933 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.3904 - accuracy: 0.8158 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.3788 - accuracy: 0.8493105/105 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8381
Epoch 29/100
  1/105 [..............................] - ETA: 0s - loss: 0.4220 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8919 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.3627 - accuracy: 0.8784105/105 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8571
Epoch 30/100
  1/105 [..............................] - ETA: 0s - loss: 0.3984 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.3397 - accuracy: 0.8158 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.3764 - accuracy: 0.8784105/105 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8762
Epoch 31/100
  1/105 [..............................] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2879 - accuracy: 0.8947 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.3355 - accuracy: 0.8933105/105 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8571
Epoch 32/100
  1/105 [..............................] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.3847 - accuracy: 0.8108 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.3732 - accuracy: 0.8919105/105 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8952
Epoch 33/100
  1/105 [..............................] - ETA: 0s - loss: 0.3247 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.4082 - accuracy: 0.8529 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.3795 - accuracy: 0.8696105/105 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.9048105/105 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.9048
Epoch 34/100
  1/105 [..............................] - ETA: 0s - loss: 0.5743 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.3124 - accuracy: 0.9189 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.3320 - accuracy: 0.9178105/105 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.9143
Epoch 35/100
  1/105 [..............................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2869 - accuracy: 0.9211 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.3338 - accuracy: 0.9315105/105 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.9238
Epoch 36/100
  1/105 [..............................] - ETA: 0s - loss: 0.4192 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.3779 - accuracy: 0.9143 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.3467 - accuracy: 0.9306105/105 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.9238
Epoch 37/100
  1/105 [..............................] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.3638 - accuracy: 0.9459 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.3328 - accuracy: 0.9155105/105 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.9333
Epoch 38/100
  1/105 [..............................] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2979 - accuracy: 1.0000 67/105 [==================&gt;...........] - ETA: 0s - loss: 0.3161 - accuracy: 0.9552103/105 [============================&gt;.] - ETA: 0s - loss: 0.3183 - accuracy: 0.9417105/105 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.9429
Epoch 39/100
  1/105 [..............................] - ETA: 0s - loss: 0.4674 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.3000 - accuracy: 1.0000 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.3097 - accuracy: 0.9577105/105 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.9429
Epoch 40/100
  1/105 [..............................] - ETA: 0s - loss: 0.2712 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.3118 - accuracy: 0.9211 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.2834 - accuracy: 0.9595105/105 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.9429
Epoch 41/100
  1/105 [..............................] - ETA: 0s - loss: 0.0374 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.2786 - accuracy: 0.9231 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.2891 - accuracy: 0.9595105/105 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.9429
Epoch 42/100
  1/105 [..............................] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8889 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.2947 - accuracy: 0.9429103/105 [============================&gt;.] - ETA: 0s - loss: 0.2919 - accuracy: 0.9515105/105 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.9524
Epoch 43/100
  1/105 [..............................] - ETA: 0s - loss: 0.0327 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2662 - accuracy: 0.9474 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.2682 - accuracy: 0.9589105/105 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.9429
Epoch 44/100
  1/105 [..............................] - ETA: 0s - loss: 0.3170 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2933 - accuracy: 0.9189 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.3016 - accuracy: 0.9178105/105 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.9429
Epoch 45/100
  1/105 [..............................] - ETA: 0s - loss: 0.0122 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.2925 - accuracy: 0.8824 68/105 [==================&gt;...........] - ETA: 0s - loss: 0.2991 - accuracy: 0.9118102/105 [============================&gt;.] - ETA: 0s - loss: 0.2701 - accuracy: 0.9412105/105 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9429
Epoch 46/100
  1/105 [..............................] - ETA: 0s - loss: 0.7602 - accuracy: 0.0000e+00 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.2693 - accuracy: 0.9167     71/105 [===================&gt;..........] - ETA: 0s - loss: 0.2659 - accuracy: 0.9437105/105 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.9524
Epoch 47/100
  1/105 [..............................] - ETA: 0s - loss: 0.3412 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2269 - accuracy: 0.9459 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.2488 - accuracy: 0.9595105/105 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9429
Epoch 48/100
  1/105 [..............................] - ETA: 0s - loss: 0.3265 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.2489 - accuracy: 1.0000 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.2587 - accuracy: 0.9726105/105 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.9619
Epoch 49/100
  1/105 [..............................] - ETA: 0s - loss: 0.2798 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2114 - accuracy: 0.9474 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.2356 - accuracy: 0.9565104/105 [============================&gt;.] - ETA: 0s - loss: 0.2407 - accuracy: 0.9519105/105 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.9524
Epoch 50/100
  1/105 [..............................] - ETA: 0s - loss: 0.3788 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2225 - accuracy: 0.9474 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.2171 - accuracy: 0.9730105/105 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9619
Epoch 51/100
  1/105 [..............................] - ETA: 0s - loss: 0.3402 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.2229 - accuracy: 0.9714 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.2391 - accuracy: 0.9583105/105 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9619
Epoch 52/100
  1/105 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2443 - accuracy: 0.9459 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.2375 - accuracy: 0.9722105/105 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9714
Epoch 53/100
  1/105 [..............................] - ETA: 0s - loss: 0.1910 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2392 - accuracy: 0.9730 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.2294 - accuracy: 0.9726105/105 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9714
Epoch 54/100
  1/105 [..............................] - ETA: 0s - loss: 0.9218 - accuracy: 0.0000e+00 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2333 - accuracy: 0.9459     72/105 [===================&gt;..........] - ETA: 0s - loss: 0.2060 - accuracy: 0.9722105/105 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9619
Epoch 55/100
  1/105 [..............................] - ETA: 0s - loss: 0.9462 - accuracy: 0.0000e+00 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9487     75/105 [====================&gt;.........] - ETA: 0s - loss: 0.2133 - accuracy: 0.9467105/105 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9619
Epoch 56/100
  1/105 [..............................] - ETA: 0s - loss: 0.0165 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9737 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.1930 - accuracy: 0.9865105/105 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9714
Epoch 57/100
  1/105 [..............................] - ETA: 0s - loss: 0.2111 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1862 - accuracy: 0.9737 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.2006 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9714
Epoch 58/100
  1/105 [..............................] - ETA: 0s - loss: 0.0644 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.1680 - accuracy: 1.0000 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.2074 - accuracy: 0.9583105/105 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9619
Epoch 59/100
  1/105 [..............................] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1491 - accuracy: 1.0000 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.1819 - accuracy: 0.9714105/105 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9714
Epoch 60/100
  1/105 [..............................] - ETA: 0s - loss: 0.3080 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1975 - accuracy: 0.9474 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.1718 - accuracy: 0.9589105/105 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9714
Epoch 61/100
  1/105 [..............................] - ETA: 0s - loss: 0.2903 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1729 - accuracy: 0.9444 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.1884 - accuracy: 0.9577102/105 [============================&gt;.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9706105/105 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9714
Epoch 62/100
  1/105 [..............................] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.2041 - accuracy: 0.9459 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.1768 - accuracy: 0.9571105/105 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9619
Epoch 63/100
  1/105 [..............................] - ETA: 0s - loss: 0.1379 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.1591 - accuracy: 0.9697 67/105 [==================&gt;...........] - ETA: 0s - loss: 0.1644 - accuracy: 0.9701105/105 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9714
Epoch 64/100
  1/105 [..............................] - ETA: 0s - loss: 0.1658 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1527 - accuracy: 0.9737 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.1721 - accuracy: 0.9600105/105 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9619
Epoch 65/100
  1/105 [..............................] - ETA: 0s - loss: 0.3265 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.1616 - accuracy: 0.9730 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.1492 - accuracy: 0.9722105/105 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9619
Epoch 66/100
  1/105 [..............................] - ETA: 0s - loss: 0.2516 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.1712 - accuracy: 0.9714 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.1517 - accuracy: 0.9710105/105 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9714
Epoch 67/100
  1/105 [..............................] - ETA: 0s - loss: 0.1713 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1738 - accuracy: 0.9444 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.1686 - accuracy: 0.9452105/105 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9524
Epoch 68/100
  1/105 [..............................] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.0921 - accuracy: 1.0000 68/105 [==================&gt;...........] - ETA: 0s - loss: 0.1187 - accuracy: 0.9853 93/105 [=========================&gt;....] - ETA: 0s - loss: 0.1437 - accuracy: 0.9677105/105 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9619
Epoch 69/100
  1/105 [..............................] - ETA: 0s - loss: 0.0310 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1354 - accuracy: 1.0000 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.1422 - accuracy: 0.9726105/105 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9714
Epoch 70/100
  1/105 [..............................] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.1298 - accuracy: 0.9730 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.1457 - accuracy: 0.9722105/105 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9714
Epoch 71/100
  1/105 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1443 - accuracy: 0.9737 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9865105/105 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9714
Epoch 72/100
  1/105 [..............................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.1220 - accuracy: 1.0000 66/105 [=================&gt;............] - ETA: 0s - loss: 0.1116 - accuracy: 0.9848102/105 [============================&gt;.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9706105/105 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9714
Epoch 73/100
  1/105 [..............................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1359 - accuracy: 0.9444 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.1343 - accuracy: 0.9589105/105 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9714
Epoch 74/100
  1/105 [..............................] - ETA: 0s - loss: 0.2570 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.1498 - accuracy: 0.9487 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.1311 - accuracy: 0.9733105/105 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9714
Epoch 75/100
  1/105 [..............................] - ETA: 0s - loss: 0.1687 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.1009 - accuracy: 1.0000 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.1360 - accuracy: 0.9714105/105 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9714
Epoch 76/100
  1/105 [..............................] - ETA: 0s - loss: 0.0469 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1536 - accuracy: 0.9722 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.1419 - accuracy: 0.9577105/105 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9714
Epoch 77/100
  1/105 [..............................] - ETA: 0s - loss: 0.6234 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9429 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.1183 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9714
Epoch 78/100
  1/105 [..............................] - ETA: 0s - loss: 8.2685e-04 - accuracy: 1.0000 34/105 [========&gt;.....................] - ETA: 0s - loss: 0.1318 - accuracy: 0.9412     71/105 [===================&gt;..........] - ETA: 0s - loss: 0.1185 - accuracy: 0.9437105/105 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9619
Epoch 79/100
  1/105 [..............................] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1121 - accuracy: 0.9737 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.1295 - accuracy: 0.9726105/105 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9714
Epoch 80/100
  1/105 [..............................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.1037 - accuracy: 1.0000 76/105 [====================&gt;.........] - ETA: 0s - loss: 0.1217 - accuracy: 0.9737105/105 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9714
Epoch 81/100
  1/105 [..............................] - ETA: 0s - loss: 0.2320 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.1739 - accuracy: 0.9394 69/105 [==================&gt;...........] - ETA: 0s - loss: 0.1433 - accuracy: 0.9565105/105 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9714
Epoch 82/100
  1/105 [..............................] - ETA: 0s - loss: 0.0545 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.1271 - accuracy: 0.9577105/105 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9714
Epoch 83/100
  1/105 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.0916 - accuracy: 0.9722 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.0787 - accuracy: 0.9863105/105 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9619
Epoch 84/100
  1/105 [..............................] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.0975 - accuracy: 0.9737 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.1089 - accuracy: 0.9733105/105 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9619
Epoch 85/100
  1/105 [..............................] - ETA: 0s - loss: 0.0208 - accuracy: 1.0000 39/105 [==========&gt;...................] - ETA: 0s - loss: 0.0751 - accuracy: 0.9744 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.0993 - accuracy: 0.9595105/105 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9619
Epoch 86/100
  1/105 [..............................] - ETA: 0s - loss: 0.0383 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.0696 - accuracy: 0.9737 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.0811 - accuracy: 0.9733105/105 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9619
Epoch 87/100
  1/105 [..............................] - ETA: 0s - loss: 0.0512 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1501 - accuracy: 0.9444 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.1136 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9714
Epoch 88/100
  1/105 [..............................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.1163 - accuracy: 0.9577105/105 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9619
Epoch 89/100
  1/105 [..............................] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000 29/105 [=======&gt;......................] - ETA: 0s - loss: 0.1238 - accuracy: 0.9655 66/105 [=================&gt;............] - ETA: 0s - loss: 0.1165 - accuracy: 0.9545103/105 [============================&gt;.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9612105/105 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9619
Epoch 90/100
  1/105 [..............................] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.1295 - accuracy: 0.9474 74/105 [====================&gt;.........] - ETA: 0s - loss: 0.1185 - accuracy: 0.9459105/105 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9619105/105 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9619
Epoch 91/100
  1/105 [..............................] - ETA: 0s - loss: 0.1056 - accuracy: 1.0000 35/105 [=========&gt;....................] - ETA: 0s - loss: 0.0876 - accuracy: 1.0000 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.1097 - accuracy: 0.9583104/105 [============================&gt;.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9615105/105 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9619
Epoch 92/100
  1/105 [..............................] - ETA: 0s - loss: 0.2559 - accuracy: 1.0000 33/105 [========&gt;.....................] - ETA: 0s - loss: 0.0924 - accuracy: 1.0000 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.0872 - accuracy: 0.9857105/105 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9619105/105 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9619
Epoch 93/100
  1/105 [..............................] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.0708 - accuracy: 0.9730 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.0927 - accuracy: 0.9726105/105 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9619
Epoch 94/100
  1/105 [..............................] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.0863 - accuracy: 0.9737 75/105 [====================&gt;.........] - ETA: 0s - loss: 0.1108 - accuracy: 0.9467105/105 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9619
Epoch 95/100
  1/105 [..............................] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1221 - accuracy: 0.9444 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.0846 - accuracy: 0.9718105/105 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9619
Epoch 96/100
  1/105 [..............................] - ETA: 0s - loss: 0.1008 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.0750 - accuracy: 0.9722 72/105 [===================&gt;..........] - ETA: 0s - loss: 0.0808 - accuracy: 0.9583105/105 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9619
Epoch 97/100
  1/105 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 36/105 [=========&gt;....................] - ETA: 0s - loss: 0.1067 - accuracy: 0.9444 70/105 [===================&gt;..........] - ETA: 0s - loss: 0.0914 - accuracy: 0.9714105/105 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9619
Epoch 98/100
  1/105 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.0585 - accuracy: 1.0000 71/105 [===================&gt;..........] - ETA: 0s - loss: 0.0892 - accuracy: 0.9577100/105 [===========================&gt;..] - ETA: 0s - loss: 0.0969 - accuracy: 0.9600105/105 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9619
Epoch 99/100
  1/105 [..............................] - ETA: 0s - loss: 0.0250 - accuracy: 1.0000 37/105 [=========&gt;....................] - ETA: 0s - loss: 0.1040 - accuracy: 0.9459 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.0988 - accuracy: 0.9452105/105 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9619
Epoch 100/100
  1/105 [..............................] - ETA: 0s - loss: 0.4865 - accuracy: 1.0000 38/105 [=========&gt;....................] - ETA: 0s - loss: 0.0803 - accuracy: 0.9737 73/105 [===================&gt;..........] - ETA: 0s - loss: 0.0794 - accuracy: 0.9726105/105 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9619
Train loss: 0.08602090924978256
Train accuracy: 0.961904764175415
Test loss: 0.09694475680589676
Test accuracy: 0.9777777791023254
</pre>
</div>
</div>



<div id="outline-container-orgc07a8f2" class="outline-4">
<h4 id="orgc07a8f2">Model Optimization</h4>
<div class="outline-text-4" id="text-orgc07a8f2">
<ul class="org-ul">
<li>Pruning (from Keras website);
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/model_optimization/guide/pruning">overview</a>, <a href="https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide">guide</a> and <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras">example</a>.</li>
</ul></li>
</ul>


<div class="org-src-container">
<pre class="src src-python" id="orgf11339f"><span style="color: #0000FF;">import</span> os
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> sklearn <span style="color: #0000FF;">import</span> datasets
<span style="color: #0000FF;">from</span> sklearn.model_selection <span style="color: #0000FF;">import</span> train_test_split
<span style="color: #0000FF;">from</span> sklearn.preprocessing <span style="color: #0000FF;">import</span> OneHotEncoder, MinMaxScaler, StandardScaler

<span style="color: #0000FF;">from</span> keras.models <span style="color: #0000FF;">import</span> Sequential
<span style="color: #0000FF;">from</span> keras.layers <span style="color: #0000FF;">import</span> Dense

<span style="color: #0000FF;">import</span> tensorflow <span style="color: #0000FF;">as</span> tf


<span style="color: #BA36A5;">data</span> = datasets.load_iris()

<span style="color: #BA36A5;">X</span> = data[<span style="color: #008000;">'data'</span>]
<span style="color: #BA36A5;">Y</span> = data[<span style="color: #008000;">'target'</span>]

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">use and the scaled input the encoded output</span>
<span style="color: #BA36A5;">enc</span> = OneHotEncoder()
<span style="color: #BA36A5;">Y_enc</span> = enc.fit_transform(Y[:, np.newaxis]).toarray()
<span style="color: #BA36A5;">Y</span> = Y_enc

<span style="color: #BA36A5;">scaler</span> = MinMaxScaler()
<span style="color: #BA36A5;">X_scaled</span> = scaler.fit_transform(X)
<span style="color: #BA36A5;">X</span> = X_scaled

<span style="color: #BA36A5;">X_train</span>, <span style="color: #BA36A5;">X_test</span>, <span style="color: #BA36A5;">Y_train</span>, <span style="color: #BA36A5;">Y_test</span> = train_test_split(X, Y, test_size=0.3, random_state=0)

<span style="color: #BA36A5;">num_features</span> = X.shape[1]
<span style="color: #BA36A5;">num_classes</span> = Y.shape[1]

<span style="color: #BA36A5;">batch_size</span> = 1
<span style="color: #BA36A5;">epochs</span> = 100


<span style="color: #BA36A5;">model</span> = Sequential()
model.add(Dense(5, input_dim=num_features, activation=<span style="color: #008000;">'tanh'</span>))
model.add(Dense(num_classes, activation=<span style="color: #008000;">'softmax'</span>))
model.summary()

model.<span style="color: #006FE0;">compile</span>(loss=<span style="color: #008000;">'categorical_crossentropy'</span>, optimizer=<span style="color: #008000;">'adam'</span>, metrics=[<span style="color: #008000;">'accuracy'</span>])

<span style="color: #BA36A5;">history</span> = model.fit(X_train, Y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    )

<span style="color: #BA36A5;">score_train</span> = model.evaluate(X_train, Y_train, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train loss:'</span>, score_train[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train accuracy:'</span>, score_train[1])

<span style="color: #BA36A5;">score_test</span> = model.evaluate(X_test, Y_test, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test loss:'</span>, score_test[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test accuracy:'</span>, score_test[1])

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Prune Model</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">https://medium.com/analytics-vidhya/weight-pruning-with-keras-86f742dbdb58</span>

<span style="color: #BA36A5;">pruned_model</span> = tfmot.sparsity.keras.prune_low_magnitude

<span style="color: #BA36A5;">epochs</span> = 5
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Define model for pruning</span>
<span style="color: #BA36A5;">pruning_params</span> = {
  <span style="color: #008000;">'pruning_schedule'</span>: tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,
                                                           final_sparsity=0.80,
                                                           begin_step=0,
                                                           end_step=end_step)
}

<span style="color: #BA36A5;">pruned_model</span> = prune_low_magnitude(model, **pruning_params)
</pre>
</div>

<ul class="org-ul">
<li><a href="https://www.tensorflow.org/lite/performance/post_training_quantization#integer_only">Post-training quantization</a></li>
</ul>
<div class="org-src-container">
<pre class="src src-python" id="orge018804"><span style="color: #0000FF;">import</span> os
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> sklearn <span style="color: #0000FF;">import</span> datasets
<span style="color: #0000FF;">from</span> sklearn.model_selection <span style="color: #0000FF;">import</span> train_test_split
<span style="color: #0000FF;">from</span> sklearn.preprocessing <span style="color: #0000FF;">import</span> OneHotEncoder, MinMaxScaler, StandardScaler

<span style="color: #0000FF;">from</span> keras.models <span style="color: #0000FF;">import</span> Sequential
<span style="color: #0000FF;">from</span> keras.layers <span style="color: #0000FF;">import</span> Dense

<span style="color: #0000FF;">import</span> tensorflow <span style="color: #0000FF;">as</span> tf
<span style="color: #0000FF;">import</span> ipdb

<span style="color: #BA36A5;">data</span> = datasets.load_iris()

<span style="color: #BA36A5;">X</span> = data[<span style="color: #008000;">'data'</span>]
<span style="color: #BA36A5;">Y</span> = data[<span style="color: #008000;">'target'</span>]

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">use and the scaled input the encoded output</span>
<span style="color: #BA36A5;">enc</span> = OneHotEncoder()
<span style="color: #BA36A5;">Y_enc</span> = enc.fit_transform(Y[:, np.newaxis]).toarray()
<span style="color: #BA36A5;">Y</span> = Y_enc

<span style="color: #BA36A5;">scaler</span> = MinMaxScaler()
<span style="color: #BA36A5;">X_scaled</span> = scaler.fit_transform(X)
<span style="color: #BA36A5;">X</span> = X_scaled

<span style="color: #BA36A5;">X_train</span>, <span style="color: #BA36A5;">X_test</span>, <span style="color: #BA36A5;">Y_train</span>, <span style="color: #BA36A5;">Y_test</span> = train_test_split(X, Y, test_size=0.3, random_state=0)

<span style="color: #BA36A5;">num_features</span> = X.shape[1]
<span style="color: #BA36A5;">num_classes</span> = Y.shape[1]

<span style="color: #BA36A5;">batch_size</span> = 1
<span style="color: #BA36A5;">epochs</span> = 100


<span style="color: #BA36A5;">model</span> = Sequential()
model.add(Dense(5, input_dim=num_features, activation=<span style="color: #008000;">'tanh'</span>))
model.add(Dense(num_classes, activation=<span style="color: #008000;">'softmax'</span>))
model.summary()

model.<span style="color: #006FE0;">compile</span>(loss=<span style="color: #008000;">'categorical_crossentropy'</span>, optimizer=<span style="color: #008000;">'adam'</span>, metrics=[<span style="color: #008000;">'accuracy'</span>])

<span style="color: #BA36A5;">history</span> = model.fit(X_train, Y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    )

<span style="color: #BA36A5;">score_train</span> = model.evaluate(X_train, Y_train, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train loss:'</span>, score_train[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train accuracy:'</span>, score_train[1])

<span style="color: #BA36A5;">score_test</span> = model.evaluate(X_test, Y_test, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test loss:'</span>, score_test[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test accuracy:'</span>, score_test[1])



<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Convert to TFlite</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">for more information: https://www.tensorflow.org/lite/models/convert</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">more specifically in: https://www.tensorflow.org/lite/models/convert/convert_models</span>

<span style="color: #BA36A5;">converter</span> = tf.lite.TFLiteConverter.from_keras_model(model)
<span style="color: #BA36A5;">tflite_model</span> = converter.convert()


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Save the model.</span>
<span style="color: #BA36A5;">model_file</span> = <span style="color: #008000;">'iris_model.tflite'</span>
<span style="color: #0000FF;">with</span> <span style="color: #006FE0;">open</span>(model_file, <span style="color: #008000;">'wb'</span>) <span style="color: #0000FF;">as</span> f:
  f.write(tflite_model)


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Dynamic Range Post training quantization</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">https://www.tensorflow.org/lite/performance/post_training_quantization</span>

<span style="color: #BA36A5;">converter</span> = tf.lite.TFLiteConverter.from_keras_model(model)
<span style="color: #BA36A5;">converter.optimizations</span> = [tf.lite.Optimize.DEFAULT]
<span style="color: #BA36A5;">tflite_dynamicrange_quant_model</span> = converter.convert()


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Save the quantized model.</span>
<span style="color: #BA36A5;">dynamicrange_quant_model_file</span> = <span style="color: #008000;">'iris_model_quantized.tflite'</span>
<span style="color: #0000FF;">with</span> <span style="color: #006FE0;">open</span>(dynamicrange_quant_model_file, <span style="color: #008000;">'wb'</span>) <span style="color: #0000FF;">as</span> f:
  f.write(tflite_dynamicrange_quant_model)

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Integer-only Post training quantization</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">https://www.tensorflow.org/lite/performance/post_training_quantization#integer_only</span>

<span style="color: #BA36A5;">converter</span> = tf.lite.TFLiteConverter.from_keras_model(model)
<span style="color: #BA36A5;">converter.optimizations</span> = [tf.lite.Optimize.DEFAULT]

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">https://www.tensorflow.org/api_docs/python/tf/lite/RepresentativeDataset</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">to learn about generators: https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do</span>
<span style="color: #0000FF;">def</span> <span style="color: #006699;">representative_dataset</span>():
    <span style="color: #0000FF;">for</span> data <span style="color: #0000FF;">in</span> X_train:
      <span style="color: #0000FF;">yield</span> [data.astype(np.float32)]

<span style="color: #BA36A5;">converter.representative_dataset</span> = representative_dataset
<span style="color: #BA36A5;">converter.target_spec.supported_ops</span> = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
<span style="color: #BA36A5;">converter.inference_input_type</span> = tf.int8  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">or tf.uint8</span>
<span style="color: #BA36A5;">converter.inference_output_type</span> = tf.int8  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">or tf.uint8</span>

<span style="color: #BA36A5;">tflite_integer_quant_model</span> = converter.convert()

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Save the quantized model.</span>
<span style="color: #BA36A5;">integer_quant_model_file</span> = <span style="color: #008000;">'iris_model_integer_quantized.tflite'</span>
<span style="color: #0000FF;">with</span> <span style="color: #006FE0;">open</span>(integer_quant_model_file, <span style="color: #008000;">'wb'</span>) <span style="color: #0000FF;">as</span> f:
  f.write(tflite_integer_quant_model)
</pre>
</div>

<ul class="org-ul">
<li>Quantization-aware training (from Keras website)
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/model_optimization/guide/quantization/training">overview</a>, <a href="https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide">guide</a> and <a href="https://www.tensorflow.org/model_optimization/guide/quantization/training_example">example</a>.</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-python" id="orge5d43b6"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">based on https://www.tensorflow.org/model_optimization/guide/quantization/training_example</span>
<span style="color: #0000FF;">import</span> os
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> sklearn <span style="color: #0000FF;">import</span> datasets
<span style="color: #0000FF;">from</span> sklearn.model_selection <span style="color: #0000FF;">import</span> train_test_split
<span style="color: #0000FF;">from</span> sklearn.preprocessing <span style="color: #0000FF;">import</span> OneHotEncoder, MinMaxScaler, StandardScaler

<span style="color: #0000FF;">from</span> keras.models <span style="color: #0000FF;">import</span> Sequential
<span style="color: #0000FF;">from</span> keras.layers <span style="color: #0000FF;">import</span> Dense
<span style="color: #0000FF;">import</span> tensorflow <span style="color: #0000FF;">as</span> tf

<span style="color: #BA36A5;">data</span> = datasets.load_iris()

<span style="color: #BA36A5;">X</span> = data[<span style="color: #008000;">'data'</span>]
<span style="color: #BA36A5;">Y</span> = data[<span style="color: #008000;">'target'</span>]

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">use and the scaled input the encoded output</span>
<span style="color: #BA36A5;">enc</span> = OneHotEncoder()
<span style="color: #BA36A5;">Y_enc</span> = enc.fit_transform(Y[:, np.newaxis]).toarray()
<span style="color: #BA36A5;">Y</span> = Y_enc

<span style="color: #BA36A5;">scaler</span> = MinMaxScaler()
<span style="color: #BA36A5;">X_scaled</span> = scaler.fit_transform(X)
<span style="color: #BA36A5;">X</span> = X_scaled

<span style="color: #BA36A5;">X_train</span>, <span style="color: #BA36A5;">X_test</span>, <span style="color: #BA36A5;">Y_train</span>, <span style="color: #BA36A5;">Y_test</span> = train_test_split(X, Y, test_size=0.3, random_state=0)

<span style="color: #BA36A5;">num_features</span> = X.shape[1]
<span style="color: #BA36A5;">num_classes</span> = Y.shape[1]

<span style="color: #BA36A5;">batch_size</span> = 1
<span style="color: #BA36A5;">epochs</span> = 100


<span style="color: #BA36A5;">model</span> = Sequential()
model.add(Dense(5, input_dim=num_features, activation=<span style="color: #008000;">'tanh'</span>))
model.add(Dense(num_classes, activation=<span style="color: #008000;">'softmax'</span>))
model.summary()

model.<span style="color: #006FE0;">compile</span>(loss=<span style="color: #008000;">'categorical_crossentropy'</span>, optimizer=<span style="color: #008000;">'adam'</span>, metrics=[<span style="color: #008000;">'accuracy'</span>])

<span style="color: #BA36A5;">history</span> = model.fit(X_train, Y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    )

<span style="color: #BA36A5;">score_train</span> = model.evaluate(X_train, Y_train, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train loss:'</span>, score_train[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Train accuracy:'</span>, score_train[1])

<span style="color: #BA36A5;">score_test</span> = model.evaluate(X_test, Y_test, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test loss:'</span>, score_test[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Test accuracy:'</span>, score_test[1])



<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">import emlearn</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">cmodel = emlearn.net.convert_keras(model, method='loadable') #methods = pymodule or loadable</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">cmodel.save(file='iris_keras.h', name='iris')</span>


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*******************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Quantized aware model  (not really quantized yet)</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">******************</span>
<span style="color: #0000FF;">import</span> tensorflow_model_optimization <span style="color: #0000FF;">as</span> tfmot

<span style="color: #BA36A5;">quantize_model</span> = tfmot.quantization.keras.quantize_model

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">q_aware stands for for quantization aware.</span>
<span style="color: #BA36A5;">q_aware_model</span> = quantize_model(model)

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">`quantize_model` requires a recompile.</span>
q_aware_model.<span style="color: #006FE0;">compile</span>(optimizer=<span style="color: #008000;">'adam'</span>,
              loss=<span style="color: #008000;">'categorical_crossentropy'</span>,
              metrics=[<span style="color: #008000;">'accuracy'</span>])


q_aware_model.summary()


<span style="color: #BA36A5;">q_aware_history</span> = q_aware_model.fit(X_train, Y_train,
                    batch_size=10,
                    epochs=1,
                    verbose=1,
                    )

<span style="color: #BA36A5;">q_aware_score_train</span> = q_aware_model.evaluate(X_train, Y_train, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'q_aware_Train loss:'</span>, q_aware_score_train[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'q_aware_Train accuracy:'</span>, q_aware_score_train[1])

<span style="color: #BA36A5;">q_aware_score_test</span> = q_aware_model.evaluate(X_test, Y_test, verbose=0)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'q_aware_Test loss:'</span>, q_aware_score_test[0])
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'q_aware_Test accuracy:'</span>, q_aware_score_test[1])


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*******************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Quantized model</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">******************</span>
<span style="color: #BA36A5;">converter</span> = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)
<span style="color: #BA36A5;">converter.optimizations</span> = [tf.lite.Optimize.DEFAULT] <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">check here</span>

<span style="color: #BA36A5;">quantized_tflite_model</span> = converter.convert()


<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">******************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Testing quantized model</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">*****************</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">...</span>
</pre>
</div>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
